{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mg80x-zqiZC",
        "colab_type": "text"
      },
      "source": [
        "**Лабораторная работа №2. Реализация глубокой нейронной сети**\n",
        "1.   Реализуйте полносвязную нейронную сеть с помощью библиотеки Tensor Flow. В качестве алгоритма оптимизации можно использовать, например, стохастический градиент (Stochastic Gradient Descent, SGD). Определите количество скрытых слоев от 1 до 5, количество нейронов в каждом из слоев до нескольких сотен, а также их функции активации (кусочно-линейная, сигмоидная, гиперболический тангенс и т.д.).\n",
        "2.   Как улучшилась точность классификатора по сравнению с логистической регрессией?\n",
        "3. Используйте регуляризацию и метод сброса нейронов (dropout) для борьбы с переобучением. Как улучшилось качество классификации?\n",
        "4. Воспользуйтесь динамически изменяемой скоростью обучения (learning rate). Наилучшая точность, достигнутая с помощью данной модели составляет 97.1%. Какую точность демонстрирует Ваша реализованная модель?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdBYbDpmg_0S",
        "colab_type": "code",
        "outputId": "3c4979ef-b1d2-4645-b59b-c46c440f762f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import os\n",
        "try:\n",
        "  import wget\n",
        "except: \n",
        "  !pip install wget\n",
        "  import wget\n",
        "import tarfile\n",
        "\n",
        "\n",
        "out_dir = 'data/not_mnist'\n",
        "small_arhive = f'{out_dir}/notMNIST_small.tar.gz'\n",
        "large_arhive = f'{out_dir}/notMNIST_large.tar.gz'\n",
        "large_url = 'https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz'\n",
        "small_url = 'https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=50e0f3f3d45a0ce8bfeec8caf1f9529fa273e431678a0908ad1e120e091ed412\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBSFpzB8hVbS",
        "colab_type": "code",
        "outputId": "6af6d708-0517-4fe9-e134-3f57afc02d41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "if not os.path.exists(out_dir):\n",
        "  os.makedirs(out_dir)\n",
        "\n",
        "if not os.path.exists(small_arhive):\n",
        "  print(f\"Downloading {small_arhive}.\")\n",
        "  wget.download(small_url, small_arhive)\n",
        "  print()\n",
        "else:\n",
        "  print(f\"Skipping {small_arhive} download (already exists)\")\n",
        "\n",
        "if not os.path.exists(large_arhive):\n",
        "  print(f\"Downloading {large_arhive}.\")\n",
        "  wget.download(large_url, large_arhive)\n",
        "  print()\n",
        "else:\n",
        "  print(f\"Skipping {large_arhive} download (already exists)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data/not_mnist/notMNIST_small.tar.gz.\n",
            "\n",
            "Downloading data/not_mnist/notMNIST_large.tar.gz.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RczTDleyhsFO",
        "colab_type": "code",
        "outputId": "231b969d-9d17-4180-ec09-6bd101e94e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f\"Extracting {small_arhive}\")\n",
        "with tarfile.open(small_arhive) as tar:\n",
        "  tar.extractall(out_dir)\n",
        "\n",
        "print(f\"Extracting {large_arhive}\")\n",
        "with tarfile.open(large_arhive) as tar:\n",
        "  tar.extractall(out_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/not_mnist/notMNIST_small.tar.gz\n",
            "Extracting data/not_mnist/notMNIST_large.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybTw8UfjiD-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "def remove_duplicates(img_train, labels_train, img_test):\n",
        "    img_new, labels_new = [], []\n",
        "    test_set = {e.tostring() for e in img_test}\n",
        "    for i, (x, y) in enumerate(zip(img_train, labels_train)):\n",
        "        if x.tostring() not in test_set:\n",
        "            img_new.append(x)\n",
        "            labels_new.append(y)\n",
        "\n",
        "    print(f'Removed {img_train.shape[0] - len(img_new)} duplicated images')\n",
        "    return np.array(img_new), np.array(labels_new)\n",
        "\n",
        "def load_images(path, n):\n",
        "    labels = ['I', 'G', 'A', 'F', 'H', 'J', 'C', 'D', 'E', 'B']\n",
        "\n",
        "    x, y = [], []\n",
        "    for i, l in enumerate(labels):\n",
        "        d = Path(path) / l\n",
        "        print(f'Loading {str(d)} ', end='')\n",
        "        for j, f in zip(range(n), d.iterdir()):\n",
        "            try:\n",
        "                with Image.open(f) as img:\n",
        "                    x.append(np.array(img))\n",
        "                    y.append(i)\n",
        "            except OSError:\n",
        "                pass\n",
        "            if j % 1000 == 0:\n",
        "                print('.', end='', flush=True)\n",
        "        print(flush=True)\n",
        "    return np.array(labels), np.array(x), np.array(y)\n",
        "\n",
        "def load_not_mnist_data(path='data/not_mnist/', use_cache=True):\n",
        "    train_folder = Path(path) / 'notMNIST_large'\n",
        "    test_folder = Path(path) / 'notMNIST_small'\n",
        "\n",
        "    train_cache_file = Path(path) / 'train.npz'\n",
        "    test_cache_file = Path(path) / 'test.npz'\n",
        "\n",
        "    if train_cache_file.exists() and test_cache_file.exists() and use_cache:\n",
        "        f = np.load(train_cache_file)\n",
        "        labels, img_train, labels_train = [v for k, v in f.items()]\n",
        "        f = np.load(test_cache_file)\n",
        "        labels, img_test, labels_test = [v for k, v in f.items()]\n",
        "        print('Loaded cached arrays')\n",
        "\n",
        "    else:\n",
        "        labels, img_train, labels_train = load_images(train_folder, 10000000)\n",
        "        labels, img_test, labels_test = load_images(test_folder, 10000000)\n",
        "        np.savez(train_cache_file, labels, img_train, labels_train)\n",
        "        np.savez(test_cache_file, labels, img_test, labels_test)\n",
        "\n",
        "    return labels, img_train, labels_train, img_test, labels_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76do6zy0qvHI",
        "colab_type": "code",
        "outputId": "93ebc665-8914-4c28-b709-f84a5f5a067d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels, img_train, labels_train, img_test, labels_test = load_not_mnist_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded cached arrays\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8St8voGAs89t",
        "colab_type": "code",
        "outputId": "0c1ff686-3783-4b80-c1fa-2f5a0b10fdaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_train, labels_train = remove_duplicates(img_train, labels_train, img_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed 12213 duplicated images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy0FDL1Ou1We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def flatten(a):\n",
        "    return a.reshape(a.shape[0], a.shape[1] * a.shape[2])\n",
        "\n",
        "def load_data():\n",
        "    labels, img_train, labels_train, img_test, labels_test = load_not_mnist_data()\n",
        "    img_train, labels_train = remove_duplicates(img_train, labels_train, img_test)\n",
        "    return labels, flatten(img_train), labels_train, flatten(img_test), labels_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9udnwtbhvNur",
        "colab_type": "code",
        "outputId": "191f3112-2850-46de-dbc1-ad9088ecd37e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "labels, img_train, labels_train, img_test, labels_test = load_not_mnist_data()\n",
        "img_train, labels_train = remove_duplicates(img_train, labels_train, img_test)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded cached arrays\n",
            "Removed 12213 duplicated images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyIPNW1orV_P",
        "colab_type": "text"
      },
      "source": [
        "**Задание 1.**\n",
        "Реализуйте полносвязную нейронную сеть с помощью библиотеки Tensor Flow. В качестве алгоритма оптимизации можно использовать, например, стохастический градиент (Stochastic Gradient Descent, SGD). Определите количество скрытых слоев от 1 до 5, количество нейронов в каждом из слоев до нескольких сотен, а также их функции активации (кусочно-линейная, сигмоидная, гиперболический тангенс и т.д.).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImCvs2ZowQ99",
        "colab_type": "code",
        "outputId": "882cb740-1078-42bf-ec7b-98c1675a80c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "results = {}\n",
        "results.setdefault('val_acc', {})\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\n",
        "    tf.keras.layers.Dense(200, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
        "model.fit(x=img_train, y=labels_train, epochs=100,\n",
        "          callbacks=[callback], validation_split=0.1)\n",
        "print('\\n# Evaluate')\n",
        "result = model.evaluate(img_test, labels_test)\n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16154/16154 [==============================] - 44s 3ms/step - loss: 0.9557 - accuracy: 0.7816\n",
            "Epoch 2/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.5695 - accuracy: 0.8335\n",
            "Epoch 3/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.5467 - accuracy: 0.8385\n",
            "Epoch 4/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.5205 - accuracy: 0.8465\n",
            "Epoch 5/100\n",
            "16154/16154 [==============================] - 44s 3ms/step - loss: 0.5058 - accuracy: 0.8506\n",
            "Epoch 6/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4956 - accuracy: 0.8537\n",
            "Epoch 7/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4864 - accuracy: 0.8555\n",
            "Epoch 8/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4766 - accuracy: 0.8586\n",
            "Epoch 9/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4686 - accuracy: 0.8604\n",
            "Epoch 10/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4629 - accuracy: 0.8621\n",
            "Epoch 11/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4588 - accuracy: 0.8636\n",
            "Epoch 12/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4567 - accuracy: 0.8637\n",
            "Epoch 13/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4522 - accuracy: 0.8645\n",
            "Epoch 14/100\n",
            "16154/16154 [==============================] - 44s 3ms/step - loss: 0.4501 - accuracy: 0.8649\n",
            "Epoch 15/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4463 - accuracy: 0.8659\n",
            "Epoch 16/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4474 - accuracy: 0.8664\n",
            "Epoch 17/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4408 - accuracy: 0.8674\n",
            "Epoch 18/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4404 - accuracy: 0.8681\n",
            "Epoch 19/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4389 - accuracy: 0.8681\n",
            "Epoch 20/100\n",
            "16154/16154 [==============================] - 44s 3ms/step - loss: 0.4352 - accuracy: 0.8690\n",
            "Epoch 21/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4349 - accuracy: 0.8693\n",
            "Epoch 22/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4317 - accuracy: 0.8693\n",
            "Epoch 23/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4313 - accuracy: 0.8698\n",
            "Epoch 24/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4301 - accuracy: 0.8702\n",
            "Epoch 25/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4297 - accuracy: 0.8704\n",
            "Epoch 26/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4299 - accuracy: 0.8707\n",
            "Epoch 27/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4275 - accuracy: 0.8713\n",
            "Epoch 28/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4276 - accuracy: 0.8708\n",
            "Epoch 29/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4268 - accuracy: 0.8720\n",
            "Epoch 30/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4240 - accuracy: 0.8722\n",
            "Epoch 31/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4239 - accuracy: 0.8726\n",
            "Epoch 32/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4218 - accuracy: 0.8725\n",
            "Epoch 33/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4207 - accuracy: 0.8729\n",
            "Epoch 34/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4209 - accuracy: 0.8732\n",
            "Epoch 35/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4172 - accuracy: 0.8735\n",
            "Epoch 36/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4179 - accuracy: 0.8739\n",
            "Epoch 37/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4176 - accuracy: 0.8736\n",
            "Epoch 38/100\n",
            "16154/16154 [==============================] - 42s 3ms/step - loss: 0.4184 - accuracy: 0.8736\n",
            "Epoch 39/100\n",
            "16154/16154 [==============================] - 43s 3ms/step - loss: 0.4157 - accuracy: 0.8738\n",
            "\n",
            "# Evaluate\n",
            "586/586 [==============================] - 1s 1ms/step - loss: 0.2734 - accuracy: 0.9323\n",
            "[0.27337297797203064, 0.9323328137397766]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dRailoVrjk4",
        "colab_type": "text"
      },
      "source": [
        "**Задание 2.**\n",
        "Как улучшилась точность классификатора по сравнению с логистической регрессией?\n",
        "\n",
        "Точность классификатора повысилась на 11 процентов\n",
        "\n",
        "**Задание 3.**\n",
        "Используйте регуляризацию и метод сброса нейронов (dropout) для борьбы с переобучением. Как улучшилось качество классификации?\n",
        "\n",
        "В моей модели качество классификации не улучшилось при добавлении, скорее всего штраф был большим, и отбрасывались веса, которые могли бы описать удачнее модель, пытался уменьшать штраф, так как результат был еще меньше чем без регуляризации\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ngw6opGuPpB",
        "colab_type": "code",
        "outputId": "637bd720-adb1-4d9b-8ba9-8d6af355438a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "initializer = tf.keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "regL1 = tf.keras.regularizers.l1(0.0001)\n",
        "regL2 = tf.keras.regularizers.l2(0.0001)\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(200, \n",
        "                          activation='relu', \n",
        "                          kernel_regularizer=regL2,\n",
        "                          bias_regularizer=regL2, \n",
        "                          bias_initializer=initializer,\n",
        "                          kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dense(200, \n",
        "                          activation='relu', \n",
        "                          kernel_regularizer=regL2,\n",
        "                          bias_regularizer=regL2, \n",
        "                          bias_initializer=initializer,\n",
        "                          kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#steps_per_epoch=tf.math.ceil(train_size/BATCH_SIZE).numpy()\n",
        "#model.fit(train_dataset, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=(test_dataset))\n",
        "model2.fit(x=img_train, y=labels_train, epochs=100,\n",
        "          callbacks=[callback], validation_split=0.1)\n",
        "#model.fit(train_dataset, epochs=2, steps_per_epoch=steps_per_epoch)\n",
        "print('\\n# Evaluate')\n",
        "result2 = model2.evaluate(img_test, labels_test)\n",
        "print (result2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.7922 - accuracy: 0.8100\n",
            "Epoch 2/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5592 - accuracy: 0.8408\n",
            "Epoch 3/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5473 - accuracy: 0.8456\n",
            "Epoch 4/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5333 - accuracy: 0.8509\n",
            "Epoch 5/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5266 - accuracy: 0.8529\n",
            "Epoch 6/100\n",
            "16154/16154 [==============================] - 48s 3ms/step - loss: 0.5244 - accuracy: 0.8544\n",
            "Epoch 7/100\n",
            "16154/16154 [==============================] - 48s 3ms/step - loss: 0.5219 - accuracy: 0.8550\n",
            "Epoch 8/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5200 - accuracy: 0.8562\n",
            "Epoch 9/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5197 - accuracy: 0.8566\n",
            "Epoch 10/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5173 - accuracy: 0.8576\n",
            "Epoch 11/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5178 - accuracy: 0.8568\n",
            "Epoch 12/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5184 - accuracy: 0.8573\n",
            "Epoch 13/100\n",
            "16154/16154 [==============================] - 53s 3ms/step - loss: 0.5169 - accuracy: 0.8576\n",
            "Epoch 14/100\n",
            "16154/16154 [==============================] - 55s 3ms/step - loss: 0.5170 - accuracy: 0.8572\n",
            "Epoch 15/100\n",
            "16154/16154 [==============================] - 53s 3ms/step - loss: 0.5171 - accuracy: 0.8572\n",
            "Epoch 16/100\n",
            "16154/16154 [==============================] - 53s 3ms/step - loss: 0.5175 - accuracy: 0.8572\n",
            "\n",
            "# Evaluate\n",
            "586/586 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.9172\n",
            "[0.3239336907863617, 0.9172185659408569]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7IFZJSBn7JH",
        "colab_type": "code",
        "outputId": "592b5f56-4111-45f6-a63d-688dcb8ac140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(200, \n",
        "                          activation='relu', \n",
        "                          kernel_regularizer=regL2,\n",
        "                          bias_regularizer=regL2, \n",
        "                          bias_initializer=initializer,\n",
        "                          kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(200, \n",
        "                          activation='relu', \n",
        "                          kernel_regularizer=regL2,\n",
        "                          bias_regularizer=regL2, \n",
        "                          bias_initializer=initializer,\n",
        "                          kernel_initializer=initializer),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#steps_per_epoch=tf.math.ceil(train_size/BATCH_SIZE).numpy()\n",
        "#model.fit(train_dataset, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=(test_dataset))\n",
        "model3.fit(x=img_train, y=labels_train, epochs=100,\n",
        "          callbacks=[callback], validation_split=0.1)\n",
        "#model.fit(train_dataset, epochs=2, steps_per_epoch=steps_per_epoch)\n",
        "print('\\n# Evaluate')\n",
        "result = model3.evaluate(img_test, labels_test)\n",
        "print (result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 1.0940 - accuracy: 0.7254\n",
            "Epoch 2/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.6626 - accuracy: 0.8030\n",
            "Epoch 3/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.6378 - accuracy: 0.8119\n",
            "Epoch 4/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.6360 - accuracy: 0.8107\n",
            "Epoch 5/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.6263 - accuracy: 0.8154\n",
            "Epoch 6/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.6150 - accuracy: 0.8178\n",
            "Epoch 7/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.6083 - accuracy: 0.8191\n",
            "Epoch 8/100\n",
            "16154/16154 [==============================] - 48s 3ms/step - loss: 0.6029 - accuracy: 0.8211\n",
            "Epoch 9/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5996 - accuracy: 0.8218\n",
            "Epoch 10/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5962 - accuracy: 0.8232\n",
            "Epoch 11/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5903 - accuracy: 0.8244\n",
            "Epoch 12/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5894 - accuracy: 0.8248\n",
            "Epoch 13/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5824 - accuracy: 0.8263\n",
            "Epoch 14/100\n",
            "16154/16154 [==============================] - 51s 3ms/step - loss: 0.5805 - accuracy: 0.8262\n",
            "Epoch 15/100\n",
            "16154/16154 [==============================] - 51s 3ms/step - loss: 0.5777 - accuracy: 0.8281\n",
            "Epoch 16/100\n",
            "16154/16154 [==============================] - 51s 3ms/step - loss: 0.5761 - accuracy: 0.8284\n",
            "Epoch 17/100\n",
            "16154/16154 [==============================] - 51s 3ms/step - loss: 0.5718 - accuracy: 0.8296\n",
            "Epoch 18/100\n",
            "16154/16154 [==============================] - 51s 3ms/step - loss: 0.5705 - accuracy: 0.8299\n",
            "Epoch 19/100\n",
            "16154/16154 [==============================] - 51s 3ms/step - loss: 0.5681 - accuracy: 0.8308\n",
            "Epoch 20/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5646 - accuracy: 0.8322\n",
            "Epoch 21/100\n",
            "16154/16154 [==============================] - 49s 3ms/step - loss: 0.5633 - accuracy: 0.8324\n",
            "Epoch 22/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5681 - accuracy: 0.8318\n",
            "Epoch 23/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5593 - accuracy: 0.8339\n",
            "Epoch 24/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5604 - accuracy: 0.8337\n",
            "Epoch 25/100\n",
            "16154/16154 [==============================] - 52s 3ms/step - loss: 0.5576 - accuracy: 0.8358\n",
            "Epoch 26/100\n",
            "16154/16154 [==============================] - 52s 3ms/step - loss: 0.5569 - accuracy: 0.8361\n",
            "Epoch 27/100\n",
            "16154/16154 [==============================] - 50s 3ms/step - loss: 0.5556 - accuracy: 0.8364\n",
            "Epoch 28/100\n",
            "16154/16154 [==============================] - 54s 3ms/step - loss: 0.5524 - accuracy: 0.8375\n",
            "Epoch 29/100\n",
            "16154/16154 [==============================] - 59s 4ms/step - loss: 0.5566 - accuracy: 0.8376\n",
            "Epoch 30/100\n",
            "16154/16154 [==============================] - 55s 3ms/step - loss: 0.5534 - accuracy: 0.8374\n",
            "Epoch 31/100\n",
            "16154/16154 [==============================] - 59s 4ms/step - loss: 0.5506 - accuracy: 0.8376\n",
            "Epoch 32/100\n",
            "16154/16154 [==============================] - 54s 3ms/step - loss: 0.5474 - accuracy: 0.8389\n",
            "Epoch 33/100\n",
            "16154/16154 [==============================] - 55s 3ms/step - loss: 0.5489 - accuracy: 0.8385\n",
            "Epoch 34/100\n",
            "16154/16154 [==============================] - 55s 3ms/step - loss: 0.5483 - accuracy: 0.8380\n",
            "Epoch 35/100\n",
            "16154/16154 [==============================] - 55s 3ms/step - loss: 0.5479 - accuracy: 0.8378\n",
            "\n",
            "# Evaluate\n",
            "586/586 [==============================] - 1s 1ms/step - loss: 0.2875 - accuracy: 0.9201\n",
            "[0.28747716546058655, 0.9201025366783142]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GleUNPHys8EV",
        "colab_type": "text"
      },
      "source": [
        "**Задание 4.**\n",
        "Воспользуйтесь динамически изменяемой скоростью обучения (learning rate). Наилучшая точность, достигнутая с помощью данной модели составляет 97.1%. Какую точность демонстрирует Ваша реализованная модель?\n",
        "\n",
        "Сравнение алгоритма без динамического шага, все предыдущие были с оптимизатором adam\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPUE9uVo09kW",
        "colab_type": "code",
        "outputId": "1908ac36-ad86-48ed-97c9-8c79fd3bb306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(300, activation='relu'),\n",
        "    tf.keras.layers.Dense(300, activation='relu'),\n",
        "    tf.keras.layers.Dense(300, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "learning_rate = 0.001\n",
        "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n",
        "model4.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#steps_per_epoch=tf.math.ceil(train_size/BATCH_SIZE).numpy()\n",
        "#model.fit(train_dataset, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=(test_dataset))\n",
        "model4.fit(x=img_train, y=labels_train, epochs=100,\n",
        "          callbacks=[callback], validation_split=0.1)\n",
        "#model.fit(train_dataset, epochs=2, steps_per_epoch=steps_per_epoch)\n",
        "print('\\n# Evaluate')\n",
        "result = model4.evaluate(img_test, labels_test)\n",
        "print (result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14538/14538 [==============================] - 76s 5ms/step - loss: 0.7099 - accuracy: 0.8281 - val_loss: 3.9638 - val_accuracy: 0.3058\n",
            "Epoch 2/100\n",
            "14538/14538 [==============================] - 76s 5ms/step - loss: 0.4403 - accuracy: 0.8622 - val_loss: 3.0196 - val_accuracy: 0.4446\n",
            "Epoch 3/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.4049 - accuracy: 0.8737 - val_loss: 3.0639 - val_accuracy: 0.4615\n",
            "Epoch 4/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.3809 - accuracy: 0.8807 - val_loss: 2.5569 - val_accuracy: 0.5482\n",
            "Epoch 5/100\n",
            "14538/14538 [==============================] - 78s 5ms/step - loss: 0.3631 - accuracy: 0.8860 - val_loss: 2.8790 - val_accuracy: 0.5354\n",
            "Epoch 6/100\n",
            "14538/14538 [==============================] - 76s 5ms/step - loss: 0.3487 - accuracy: 0.8904 - val_loss: 3.0503 - val_accuracy: 0.4918\n",
            "Epoch 7/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.3365 - accuracy: 0.8938 - val_loss: 2.8967 - val_accuracy: 0.4878\n",
            "Epoch 8/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.3255 - accuracy: 0.8972 - val_loss: 2.2211 - val_accuracy: 0.5902\n",
            "Epoch 9/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.3164 - accuracy: 0.8998 - val_loss: 2.7794 - val_accuracy: 0.5264\n",
            "Epoch 10/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.3079 - accuracy: 0.9027 - val_loss: 2.3318 - val_accuracy: 0.5915\n",
            "Epoch 11/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.2996 - accuracy: 0.9049 - val_loss: 2.6329 - val_accuracy: 0.5025\n",
            "Epoch 12/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.2924 - accuracy: 0.9070 - val_loss: 2.4085 - val_accuracy: 0.5699\n",
            "Epoch 13/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2856 - accuracy: 0.9089 - val_loss: 2.5572 - val_accuracy: 0.5513\n",
            "Epoch 14/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2795 - accuracy: 0.9109 - val_loss: 2.6375 - val_accuracy: 0.5514\n",
            "Epoch 15/100\n",
            "14538/14538 [==============================] - 75s 5ms/step - loss: 0.2734 - accuracy: 0.9124 - val_loss: 2.2545 - val_accuracy: 0.5883\n",
            "Epoch 16/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.2678 - accuracy: 0.9142 - val_loss: 2.4537 - val_accuracy: 0.5674\n",
            "Epoch 17/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2624 - accuracy: 0.9160 - val_loss: 2.5731 - val_accuracy: 0.5753\n",
            "Epoch 18/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2570 - accuracy: 0.9176 - val_loss: 2.4875 - val_accuracy: 0.5720\n",
            "Epoch 19/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2524 - accuracy: 0.9190 - val_loss: 2.6938 - val_accuracy: 0.5506\n",
            "Epoch 20/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.2476 - accuracy: 0.9205 - val_loss: 2.6638 - val_accuracy: 0.5739\n",
            "Epoch 21/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.2433 - accuracy: 0.9219 - val_loss: 2.7956 - val_accuracy: 0.5338\n",
            "Epoch 22/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2388 - accuracy: 0.9231 - val_loss: 2.6273 - val_accuracy: 0.5639\n",
            "Epoch 23/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.2346 - accuracy: 0.9247 - val_loss: 2.5814 - val_accuracy: 0.5645\n",
            "Epoch 24/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2308 - accuracy: 0.9259 - val_loss: 2.5701 - val_accuracy: 0.5883\n",
            "Epoch 25/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.2266 - accuracy: 0.9272 - val_loss: 2.6839 - val_accuracy: 0.5800\n",
            "Epoch 26/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2226 - accuracy: 0.9284 - val_loss: 2.9174 - val_accuracy: 0.5160\n",
            "Epoch 27/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.2192 - accuracy: 0.9292 - val_loss: 2.5698 - val_accuracy: 0.5942\n",
            "Epoch 28/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.2159 - accuracy: 0.9301 - val_loss: 2.5828 - val_accuracy: 0.5737\n",
            "Epoch 29/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.2122 - accuracy: 0.9314 - val_loss: 2.6292 - val_accuracy: 0.5859\n",
            "Epoch 30/100\n",
            "14538/14538 [==============================] - 75s 5ms/step - loss: 0.2091 - accuracy: 0.9324 - val_loss: 2.6492 - val_accuracy: 0.5969\n",
            "Epoch 31/100\n",
            "14538/14538 [==============================] - 75s 5ms/step - loss: 0.2054 - accuracy: 0.9336 - val_loss: 3.1578 - val_accuracy: 0.5353\n",
            "Epoch 32/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.2024 - accuracy: 0.9346 - val_loss: 2.7782 - val_accuracy: 0.5645\n",
            "Epoch 33/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1992 - accuracy: 0.9355 - val_loss: 2.8469 - val_accuracy: 0.5582\n",
            "Epoch 34/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1960 - accuracy: 0.9364 - val_loss: 2.7799 - val_accuracy: 0.5772\n",
            "Epoch 35/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1929 - accuracy: 0.9376 - val_loss: 3.1547 - val_accuracy: 0.5645\n",
            "Epoch 36/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1904 - accuracy: 0.9381 - val_loss: 2.9929 - val_accuracy: 0.5758\n",
            "Epoch 37/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1872 - accuracy: 0.9392 - val_loss: 2.8968 - val_accuracy: 0.5746\n",
            "Epoch 38/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1848 - accuracy: 0.9400 - val_loss: 3.2073 - val_accuracy: 0.5380\n",
            "Epoch 39/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1824 - accuracy: 0.9407 - val_loss: 3.2207 - val_accuracy: 0.5646\n",
            "Epoch 40/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1794 - accuracy: 0.9417 - val_loss: 3.0908 - val_accuracy: 0.5815\n",
            "Epoch 41/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1769 - accuracy: 0.9424 - val_loss: 2.9356 - val_accuracy: 0.5883\n",
            "Epoch 42/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.1744 - accuracy: 0.9434 - val_loss: 3.0271 - val_accuracy: 0.5753\n",
            "Epoch 43/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.1720 - accuracy: 0.9440 - val_loss: 3.0928 - val_accuracy: 0.5462\n",
            "Epoch 44/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1696 - accuracy: 0.9448 - val_loss: 3.0603 - val_accuracy: 0.5808\n",
            "Epoch 45/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1675 - accuracy: 0.9456 - val_loss: 3.7177 - val_accuracy: 0.5089\n",
            "Epoch 46/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1652 - accuracy: 0.9461 - val_loss: 3.0598 - val_accuracy: 0.5787\n",
            "Epoch 47/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1629 - accuracy: 0.9470 - val_loss: 3.6798 - val_accuracy: 0.5230\n",
            "Epoch 48/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1608 - accuracy: 0.9478 - val_loss: 3.4252 - val_accuracy: 0.5589\n",
            "Epoch 49/100\n",
            "14538/14538 [==============================] - 75s 5ms/step - loss: 0.1584 - accuracy: 0.9483 - val_loss: 3.4208 - val_accuracy: 0.5590\n",
            "Epoch 50/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1566 - accuracy: 0.9492 - val_loss: 3.5609 - val_accuracy: 0.5536\n",
            "Epoch 51/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1547 - accuracy: 0.9494 - val_loss: 3.2792 - val_accuracy: 0.5761\n",
            "Epoch 52/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1528 - accuracy: 0.9501 - val_loss: 3.7867 - val_accuracy: 0.5449\n",
            "Epoch 53/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1505 - accuracy: 0.9508 - val_loss: 3.6727 - val_accuracy: 0.5233\n",
            "Epoch 54/100\n",
            "14538/14538 [==============================] - 75s 5ms/step - loss: 0.1486 - accuracy: 0.9516 - val_loss: 3.3847 - val_accuracy: 0.5766\n",
            "Epoch 55/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.1472 - accuracy: 0.9517 - val_loss: 3.3044 - val_accuracy: 0.5924\n",
            "Epoch 56/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1454 - accuracy: 0.9525 - val_loss: 3.6836 - val_accuracy: 0.5611\n",
            "Epoch 57/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1439 - accuracy: 0.9529 - val_loss: 3.4021 - val_accuracy: 0.5811\n",
            "Epoch 58/100\n",
            "14538/14538 [==============================] - 73s 5ms/step - loss: 0.1414 - accuracy: 0.9537 - val_loss: 3.4399 - val_accuracy: 0.5934\n",
            "Epoch 59/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.1401 - accuracy: 0.9542 - val_loss: 3.4956 - val_accuracy: 0.5864\n",
            "Epoch 60/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1382 - accuracy: 0.9546 - val_loss: 3.7009 - val_accuracy: 0.5645\n",
            "Epoch 61/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1372 - accuracy: 0.9549 - val_loss: 4.0359 - val_accuracy: 0.5765\n",
            "Epoch 62/100\n",
            "14538/14538 [==============================] - 76s 5ms/step - loss: 0.1353 - accuracy: 0.9557 - val_loss: 4.0258 - val_accuracy: 0.5450\n",
            "Epoch 63/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.1336 - accuracy: 0.9562 - val_loss: 3.5179 - val_accuracy: 0.5965\n",
            "Epoch 64/100\n",
            "14538/14538 [==============================] - 66s 5ms/step - loss: 0.1324 - accuracy: 0.9567 - val_loss: 3.8658 - val_accuracy: 0.5806\n",
            "Epoch 65/100\n",
            "14538/14538 [==============================] - 66s 5ms/step - loss: 0.1306 - accuracy: 0.9570 - val_loss: 4.0361 - val_accuracy: 0.5538\n",
            "Epoch 66/100\n",
            "14538/14538 [==============================] - 67s 5ms/step - loss: 0.1296 - accuracy: 0.9574 - val_loss: 3.9768 - val_accuracy: 0.5596\n",
            "Epoch 67/100\n",
            "14538/14538 [==============================] - 68s 5ms/step - loss: 0.1278 - accuracy: 0.9581 - val_loss: 3.8589 - val_accuracy: 0.5683\n",
            "Epoch 68/100\n",
            "14538/14538 [==============================] - 67s 5ms/step - loss: 0.1262 - accuracy: 0.9589 - val_loss: 4.1609 - val_accuracy: 0.5485\n",
            "Epoch 69/100\n",
            "14538/14538 [==============================] - 66s 5ms/step - loss: 0.1249 - accuracy: 0.9589 - val_loss: 4.4513 - val_accuracy: 0.5366\n",
            "Epoch 70/100\n",
            "14538/14538 [==============================] - 67s 5ms/step - loss: 0.1235 - accuracy: 0.9595 - val_loss: 3.7937 - val_accuracy: 0.5899\n",
            "Epoch 71/100\n",
            "14538/14538 [==============================] - 68s 5ms/step - loss: 0.1223 - accuracy: 0.9598 - val_loss: 3.8595 - val_accuracy: 0.5619\n",
            "Epoch 72/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1212 - accuracy: 0.9602 - val_loss: 3.9233 - val_accuracy: 0.5709\n",
            "Epoch 73/100\n",
            "14538/14538 [==============================] - 69s 5ms/step - loss: 0.1201 - accuracy: 0.9605 - val_loss: 3.8487 - val_accuracy: 0.6013\n",
            "Epoch 74/100\n",
            "14538/14538 [==============================] - 68s 5ms/step - loss: 0.1186 - accuracy: 0.9610 - val_loss: 4.6559 - val_accuracy: 0.5632\n",
            "Epoch 75/100\n",
            "14538/14538 [==============================] - 69s 5ms/step - loss: 0.1180 - accuracy: 0.9613 - val_loss: 4.2207 - val_accuracy: 0.5725\n",
            "Epoch 76/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.1170 - accuracy: 0.9615 - val_loss: 3.9807 - val_accuracy: 0.5704\n",
            "Epoch 77/100\n",
            "14538/14538 [==============================] - 69s 5ms/step - loss: 0.1152 - accuracy: 0.9620 - val_loss: 4.1908 - val_accuracy: 0.5484\n",
            "Epoch 78/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.1139 - accuracy: 0.9625 - val_loss: 4.3981 - val_accuracy: 0.5590\n",
            "Epoch 79/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.1135 - accuracy: 0.9625 - val_loss: 3.9252 - val_accuracy: 0.5885\n",
            "Epoch 80/100\n",
            "14538/14538 [==============================] - 69s 5ms/step - loss: 0.1125 - accuracy: 0.9629 - val_loss: 4.5508 - val_accuracy: 0.5437\n",
            "Epoch 81/100\n",
            "14538/14538 [==============================] - 69s 5ms/step - loss: 0.1112 - accuracy: 0.9634 - val_loss: 4.4530 - val_accuracy: 0.5610\n",
            "Epoch 82/100\n",
            "14538/14538 [==============================] - 69s 5ms/step - loss: 0.1096 - accuracy: 0.9640 - val_loss: 4.1170 - val_accuracy: 0.5801\n",
            "Epoch 83/100\n",
            "14538/14538 [==============================] - 68s 5ms/step - loss: 0.1083 - accuracy: 0.9644 - val_loss: 4.9726 - val_accuracy: 0.5169\n",
            "Epoch 84/100\n",
            "14538/14538 [==============================] - 69s 5ms/step - loss: 0.1084 - accuracy: 0.9644 - val_loss: 4.3088 - val_accuracy: 0.5891\n",
            "Epoch 85/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.1074 - accuracy: 0.9647 - val_loss: 4.2204 - val_accuracy: 0.5777\n",
            "Epoch 86/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.1064 - accuracy: 0.9649 - val_loss: 4.5704 - val_accuracy: 0.5616\n",
            "Epoch 87/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1053 - accuracy: 0.9655 - val_loss: 4.2248 - val_accuracy: 0.5976\n",
            "Epoch 88/100\n",
            "14538/14538 [==============================] - 74s 5ms/step - loss: 0.1040 - accuracy: 0.9656 - val_loss: 4.3814 - val_accuracy: 0.5925\n",
            "Epoch 89/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.1031 - accuracy: 0.9661 - val_loss: 4.7207 - val_accuracy: 0.5612\n",
            "Epoch 90/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.1021 - accuracy: 0.9666 - val_loss: 4.8430 - val_accuracy: 0.5688\n",
            "Epoch 91/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.1018 - accuracy: 0.9664 - val_loss: 4.7164 - val_accuracy: 0.5842\n",
            "Epoch 92/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.1005 - accuracy: 0.9670 - val_loss: 4.6680 - val_accuracy: 0.5868\n",
            "Epoch 93/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.1000 - accuracy: 0.9670 - val_loss: 5.0124 - val_accuracy: 0.5336\n",
            "Epoch 94/100\n",
            "14538/14538 [==============================] - 72s 5ms/step - loss: 0.0990 - accuracy: 0.9673 - val_loss: 4.7769 - val_accuracy: 0.5718\n",
            "Epoch 95/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.0985 - accuracy: 0.9676 - val_loss: 5.0307 - val_accuracy: 0.5454\n",
            "Epoch 96/100\n",
            "14538/14538 [==============================] - 70s 5ms/step - loss: 0.0981 - accuracy: 0.9678 - val_loss: 4.9359 - val_accuracy: 0.5619\n",
            "Epoch 97/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.0964 - accuracy: 0.9683 - val_loss: 4.6103 - val_accuracy: 0.5849\n",
            "Epoch 98/100\n",
            "14538/14538 [==============================] - 71s 5ms/step - loss: 0.0946 - accuracy: 0.9689 - val_loss: 5.0675 - val_accuracy: 0.5464\n",
            "Epoch 99/100\n",
            "14538/14538 [==============================] - 65s 4ms/step - loss: 0.0952 - accuracy: 0.9687 - val_loss: 4.9389 - val_accuracy: 0.5793\n",
            "Epoch 100/100\n",
            "14538/14538 [==============================] - 64s 4ms/step - loss: 0.0953 - accuracy: 0.9684 - val_loss: 5.1727 - val_accuracy: 0.5578\n",
            "\n",
            "# Evaluate\n",
            "586/586 [==============================] - 1s 2ms/step - loss: 0.6750 - accuracy: 0.9272\n",
            "[0.6749985814094543, 0.9272057414054871]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}